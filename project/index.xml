<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Project-rsses on siddharth&#39;s home </title>
    <link>https://tanwarsid.github.io/project/index.xml</link>
    <description>Recent content in Project-rsses on siddharth&#39;s home </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Siddharth Tanwar</copyright>
    <lastBuildDate>Wed, 27 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/project/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>ABU Robocon 2014</title>
      <link>https://tanwarsid.github.io/project/rcon14/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tanwarsid.github.io/project/rcon14/</guid>
      <description>&lt;p&gt;The contest aimed at accomplishing certain pick and place tasks on an arena using two robots (1
autonomous and 1 manual). As a 3-tier team of 30, we received Most Innovative Design award
and finished 6th among 89 participating teams at national level.&lt;/p&gt;

&lt;p&gt;Go to &lt;a href=&#34;http://students.iitk.ac.in/robocon/&#34;&gt;Project Site&lt;/a&gt;.&lt;/p&gt;

&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/laNBByqB3BE&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>ABU Robocon 2015</title>
      <link>https://tanwarsid.github.io/project/rcon15/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tanwarsid.github.io/project/rcon15/</guid>
      <description>&lt;p&gt;The objective of the project was to design and fabricate and automate two manually controlled
robots capable of playing Badminton in a Standard size Badminton court.&lt;/p&gt;

&lt;p&gt;Go to &lt;a href=&#34;http://students.iitk.ac.in/robocon/&#34;&gt;Project Site&lt;/a&gt;.&lt;/p&gt;

&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/9LFS0ITb_V4&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>ABU Robocon 2016</title>
      <link>https://tanwarsid.github.io/project/rcon16/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tanwarsid.github.io/project/rcon16/</guid>
      <description>&lt;p&gt;The objective of the pan-Asia contest was to design and manufacture an autonomous robot
(Eco robot) and a semi-autonomous robot (Hybrid robot) capable of working in coordination
to complete a particular set of tasks, where Eco robot equipped with only a single actuator for
steering was guided by driving force (wind energy) obtained from Hybrid robot. We secured 3rd
position among 108 participants at Nationals and were felicitated by SnT council, IIT Kanpur.&lt;/p&gt;

&lt;p&gt;Go to &lt;a href=&#34;http://students.iitk.ac.in/robocon/&#34;&gt;Project Site&lt;/a&gt;.&lt;/p&gt;

&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/4vAes6m6usg&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>Disparate Image Matching using Duality Descriptor</title>
      <link>https://tanwarsid.github.io/project/dude/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tanwarsid.github.io/project/dude/</guid>
      <description>&lt;p&gt;Course Project under course EE604A - Image Processing&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Followed ICIP’16 paper ”DUDE (duality descriptor): A robust descriptor for disparate images
using line segment duality” by Youngwook P Kwon et al. (&lt;a href=&#34;http://ywpkwon.github.io/publication/icip16/icip16_dude.pdf&#34;&gt;http://ywpkwon.github.io/publication/icip16/icip16_dude.pdf&lt;/a&gt;) to implement from ground-up the
author’s novel descriptor and detector algorithm in MATLAB&lt;/li&gt;
&lt;li&gt;Obtained comparable results on repeatability and mAP as obtained by the author&lt;/li&gt;
&lt;li&gt;Used other existing feature descriptors - SIFT, SURF, MSER, SYM-I and SYM-G to compare
against our implementation of DUDE&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Check out the detailed report &lt;a href=&#34;ee604_report_group07.pdf&#34;&gt;here&lt;/a&gt; and presentation &lt;a href=&#34;EE604_Presentation.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Good and Evil</title>
      <link>https://tanwarsid.github.io/project/eng/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tanwarsid.github.io/project/eng/</guid>
      <description>&lt;p&gt;Course Project under course ENG458 - Literature and the Individual&lt;/p&gt;

&lt;p&gt;The conflict between good and evil has been thematized by writers since earliest times understood
ofcourse in a religious context. There are several variations on this conflict, one being the battle
between individuals or ideologies, with one side good, the other evil. Another variation is the inner
struggle in characters (and by extension, humans in reality) between good and evil. What we regard
as good is a peaceful order with the idea of a “rule of law”. Culture strives to establish a boundary
between itself and savagery. The manifestations of savegery are called &amp;ldquo;crimes&amp;rdquo; which we consider
evil. And thus there exists this conflict between two competing impulses within all human beings:
the instinct to live by rules, act peacefully, follow moral commands, and value the good of the group
against the instinct to gratify one’s immediate desires, act violently to obtain supremacy over others,
and enforce one’s will. Through my study of the 1954 Novel by Nobel prize winning English author
William Goulding&amp;rsquo;s Lord of the Flies I intend to explore the qualities of human nature and the
conflicting state within each character. The book grapples with the underlying theme or order vs
chaos and loss of innocence when a small group of schoolboys find themselves stranded on an
island after a planecrash. Through their story of existence in a community without boundaries, we
can get a better understanding of the need of a social, political and moral construct within us and
our society.&lt;/p&gt;

&lt;p&gt;Check out the detailed report &lt;a href=&#34;lord_of_the_flies.pdf&#34;&gt;here&lt;/a&gt; and presentation &lt;a href=&#34;Lord of the Flies.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intelligent Ground Vehicle Competition</title>
      <link>https://tanwarsid.github.io/project/igvc/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tanwarsid.github.io/project/igvc/</guid>
      <description>&lt;p&gt;Work in progress.&lt;/p&gt;

&lt;p&gt;Check out the competition &lt;a href=&#34;http://www.igvc.org/&#34;&gt;website&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Marker based Localization of a Quadrotor</title>
      <link>https://tanwarsid.github.io/project/quadloc/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tanwarsid.github.io/project/quadloc/</guid>
      <description>&lt;p&gt;Course Project under course EE698G - Probabilistic Mobile Robotics&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Followed ICRA’15 paper ”Precise quadrotor autonomous landing with SRUKF vision perception”
by S. Yang et al. to implement a high level control pipeline on a quadrotor&lt;/li&gt;
&lt;li&gt;Used Aruco Markers and library in ROS framework to estimate pose from images and experimented
by fusing this with onboard IMU and Sonar sensor data using Extended Kalman Filter
(EKF), Unscented Kalman Filter (UKF) and Square-Root Unscented Kalman Filter (SRUKF)&lt;/li&gt;
&lt;li&gt;Our team of two won the &lt;strong&gt;Best Presentation Award&lt;/strong&gt; for the project&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Check out the detailed report &lt;a href=&#34;ee698g_project_report.pdf&#34;&gt;here&lt;/a&gt; and presentation &lt;a href=&#34;EE698G_Presentation.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Obstacle Detection using Cascade Classifiers</title>
      <link>https://tanwarsid.github.io/project/cs365/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tanwarsid.github.io/project/cs365/</guid>
      <description>&lt;p&gt;Course Project under course CS365A - Artificial Intelligence Programming&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Trained Cascade Classifiers on features (HOG, Haar and LBP) to detect cars in images&lt;/li&gt;
&lt;li&gt;Worked with the KITTI Vision Benchmark Suite - Object Detection Evaluation 2012 dataset&lt;/li&gt;
&lt;li&gt;Partitioned Point Cloud data to identify obstacles using Velodyne Height Map algorithm (&amp;ldquo;&lt;a href=&#34;http://wiki.ros.org/velodyne_height_map&amp;quot;&#34;&gt;http://wiki.ros.org/velodyne_height_map&amp;quot;&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Processed LIDAR scan data using graph based technique to identify ROIs (Regions of Interest)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Check out the detailed report &lt;a href=&#34;cs365_report.pdf&#34;&gt;here&lt;/a&gt; and poster &lt;a href=&#34;cs365_poster.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sensory fusion, Pose Estimation and Controller Design on Quadrotors</title>
      <link>https://tanwarsid.github.io/project/quad/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tanwarsid.github.io/project/quad/</guid>
      <description>&lt;p&gt;The project aimed at autonomous indoor and outdoor navigation of an Asctec Pelican quadrotor
equipped with GPS, IMU and visual and ultrasonic sensors.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Implemented SLAM based algorithm SVO (Semi-direct Monocular Visual Odometry) using ROS framework and OpenCV on Asctec Pelican quadrotor to estimate pose in an outdoor environment&lt;/li&gt;
&lt;li&gt;Fused data obtained from GPS, monocular bottom facing camera and IMU using Extended Kalman Filter to refine results&lt;/li&gt;
&lt;li&gt;Simulated a cascade PID position controller of the Quadrotor on Matlab-Simulink&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Visual odometry for cars</title>
      <link>https://tanwarsid.github.io/project/vo/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tanwarsid.github.io/project/vo/</guid>
      <description>&lt;p&gt;The project aimed at estimating the pose of a vehicle by means of an on-board forward facing
camera and sensory fusion with an onboard IMU to handle the scale estimation problem.
Further obstacle detection and avoidance using LIDAR sensors was also done as an extension. This was a sub-part to a
larger problem statement-”Mahindra Rise Challenge” to build an autonomous car.&lt;/p&gt;

&lt;p&gt;Check out the detailed report &lt;a href=&#34;vo_report.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>YOLO: real-time object detection</title>
      <link>https://tanwarsid.github.io/project/yolo/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://tanwarsid.github.io/project/yolo/</guid>
      <description>&lt;p&gt;Course Project under course CS698N - Recent Advances in Computer Vision&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Followed CVPR’16 paper ”You only look once: Unified, real-time object detection” by Joseph
Redmon et al.(&lt;a href=&#34;http://pjreddie.com/media/files/papers/yolo_1.pdf&#34;&gt;http://pjreddie.com/media/files/papers/yolo_1.pdf&lt;/a&gt;), training and testing YOLO and tiny-YOLO CNN models on PASCAL VOC
2012 Object Detection Dataset&lt;/li&gt;
&lt;li&gt;Trained and obtained detection results on the object detection benchmark KITTI by using a
YOLO network pre-trained on ImageNet&lt;/li&gt;
&lt;li&gt;Did an extensive parameter study on YOLO, studying the changes observed on increasing/decreasing
the grid resolution and increasing number of bounding boxes per grid cell&lt;/li&gt;
&lt;li&gt;Our trained Tiny-YOLO model runs at around 50-70 fps on NVIDIA GeForce GTX 760 GPU
with mAP 44.65% on PASCAL VOC 2012 validation dataset&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Check out the detailed report &lt;a href=&#34;cs698n_final-report.pdf&#34;&gt;here&lt;/a&gt; and presentation &lt;a href=&#34;CS698N_Final_Presentation.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;YOLO : &lt;a href=&#34;http://pjreddie.com/darknet/yolo/&#34;&gt;http://pjreddie.com/darknet/yolo/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
